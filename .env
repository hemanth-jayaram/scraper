# S3 Configuration for Article Scraper
# This file contains the S3 settings for the Ultimate Scraper V2 Web Interface

# Enable S3 upload (set to 'true' to upload articles to S3)
S3_UPLOAD_ENABLED=true

# S3 Bucket Configuration - CHANGE THESE VALUES
S3_BUCKET_NAME=bockscraper
AWS_REGION=us-east-1

# AWS Credentials (choose one method below)
# Method 1: Environment variables (update with your actual credentials)
# AWS_ACCESS_KEY_ID=your-access-key-id
# AWS_SECRET_ACCESS_KEY=your-secret-access-key

# Alternative credential methods:
# Method 2: AWS credentials file (~/.aws/credentials) - Recommended
# Method 3: IAM role (if running on EC2) - Best for production

# Optional: S3 Key Prefix (auto-generated with timestamp if not set)
# S3_KEY_PREFIX=articles/custom-prefix

# Scraping Performance Settings
CONCURRENT_REQUESTS=64
CONCURRENT_REQUESTS_PER_DOMAIN=32
DOWNLOAD_DELAY=0
MAX_ARTICLES=40
SUMMARY_ENABLED=false

# Configuration Notes:
# 1. When S3_UPLOAD_ENABLED=true, articles are uploaded to S3 after scraping
# 2. The web interface downloads from S3 to local machine when you click "Download from S3"
# 3. Ensure your AWS credentials have these S3 permissions:
#    - s3:PutObject, s3:PutObjectAcl, s3:GetObject, s3:ListBucket
# 4. Articles are organized in S3 as: s3://bucket-name/session_TIMESTAMP/
